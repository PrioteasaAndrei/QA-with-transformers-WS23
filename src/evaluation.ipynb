{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain_community.vectorstores import ElasticsearchStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from elasticsearch import Elasticsearch\n",
    "from getpass import getpass\n",
    "from utils import *\n",
    "from dotenv import load_dotenv\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "HUGGINGFACE_TOKEN = os.getenv('HUGGINGFACE_TOKEN')\n",
    "HUGGINGFACE_USERNAME = os.getenv('HUGGINGFACE_USERNAME')\n",
    "HUGGINGFACE_DATASET_NAME = os.getenv('HUGGINGFACE_DATASET_NAME')\n",
    "ELASTIC_CLOUD_ID = os.getenv('ELASTIC_CLOUD_ID')\n",
    "ELASTIC_API_KEY = os.getenv('ELASTIC_API_KEY')\n",
    "QA_VALIDATION_DATASET = os.getenv('QA_VALIDATION_DATASET')\n",
    "QA_VALIDATION_TOKEN = os.getenv('QA_VALIDATION_TOKEN')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "model_name = \"NeuML/pubmedbert-base-embeddings\"\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pprint import pprint\n",
    "\n",
    "# Validation dataset (without RAG answers): https://huggingface.co/datasets/prio7777777/pubmed-qa-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample on how to run a validation for a given configuration\\nNOTE: this has not been tested holistically, but the code should work\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Example on how to run a validation for a given configuration\n",
    "NOTE: this has not been tested holistically, but the code should work\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"NeuML/pubmedbert-base-embeddings\"\n",
    "device = 'cuda:0'\n",
    "model_id = \"llama2:latest\" \n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device}\n",
    ")\n",
    "\n",
    "indexes = ['pubmedbert-sentence-transformer-50','pubmedbert-sentence-transformer-400','pubmedbert-recursive-character-400-overlap-50']\n",
    "# indexes = ['pubmedbert-sentence-transformer-100']\n",
    "## define the LLM model to use | later this can be overwritten by the user\n",
    "# llm = prepare_llm(HUGGINGFACE_TOKEN,model_id=model_id,use_openai=True)\n",
    "# llm = Ollama(model = \"llama2:latest\")\n",
    "llm = ChatOpenAI(temperature = 0, openai_api_key = OPENAI_API_KEY)\n",
    "\n",
    "## create configuration for the run_config function\n",
    "save_path = '../data/chunking_test.csv'\n",
    "save_path_result = \"../data/chunking_test_formatted.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the influence of chunking size and chunk overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunking_configuration_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000001', 'cluster_name': '3799852da3b9401fb819ca73ae522ae6', 'cluster_uuid': 'okQgd_O8RiqhrBY6O1QGQg', 'version': {'number': '8.12.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '48a287ab9497e852de30327444b0809e55d46466', 'build_date': '2024-02-19T10:04:32.774273190Z', 'build_snapshot': False, 'lucene_version': '9.9.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "generate RAG answers: 100%|██████████| 67/67 [02:46<00:00,  2.48s/it]\n",
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8996de40afda41ccb54dac509a7a8573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4567' coro=<AsyncClient.aclose() done, defined at c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1181, in aclose\n",
      "    self._transport.close()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000001', 'cluster_name': '3799852da3b9401fb819ca73ae522ae6', 'cluster_uuid': 'okQgd_O8RiqhrBY6O1QGQg', 'version': {'number': '8.12.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '48a287ab9497e852de30327444b0809e55d46466', 'build_date': '2024-02-19T10:04:32.774273190Z', 'build_snapshot': False, 'lucene_version': '9.9.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "generate RAG answers: 100%|██████████| 67/67 [02:39<00:00,  2.37s/it]\n",
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0142ac50471d4d3185af9a90728353d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000001', 'cluster_name': '3799852da3b9401fb819ca73ae522ae6', 'cluster_uuid': 'okQgd_O8RiqhrBY6O1QGQg', 'version': {'number': '8.12.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '48a287ab9497e852de30327444b0809e55d46466', 'build_date': '2024-02-19T10:04:32.774273190Z', 'build_snapshot': False, 'lucene_version': '9.9.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "generate RAG answers: 100%|██████████| 67/67 [02:19<00:00,  2.09s/it]\n",
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42919a395f31482b874ac76f3487be54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6258' coro=<AsyncClient.aclose() done, defined at c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1181, in aclose\n",
      "    self._transport.close()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6260' coro=<AsyncClient.aclose() done, defined at c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1181, in aclose\n",
      "    self._transport.close()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "for index_name in indexes:\n",
    "    elastic_vector_search = ElasticsearchStore(\n",
    "        es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings,\n",
    "        es_api_key=ELASTIC_API_KEY,\n",
    "    )\n",
    "\n",
    "    print(elastic_vector_search.client.info())\n",
    "\n",
    "\n",
    "    config_1 = {\n",
    "        \"index_name\": index_name,\n",
    "        'evaluation_dataset_path': QA_VALIDATION_DATASET,\n",
    "        'HUGGINGFACE_TOKEN': HUGGINGFACE_TOKEN,\n",
    "        'HUGGINGFACE_DATASET_NAME': HUGGINGFACE_DATASET_NAME,\n",
    "        'llm': llm,\n",
    "        'QA_VALIDATION_TOKEN': QA_VALIDATION_TOKEN,\n",
    "        'save_path': save_path,\n",
    "        'max_retrieved_docs': 3,\n",
    "        'OPENAI_API_KEY': OPENAI_API_KEY\n",
    "    }\n",
    "\n",
    "    answers = run_config(elastic_vector_search=elastic_vector_search,\n",
    "                     use_ensemble_retriever=False,\n",
    "                     verbose=False,\n",
    "                     save=True,\n",
    "                     **config_1)\n",
    "\n",
    "        \n",
    "    config_2 = {\n",
    "        'QA_VALIDATION_TOKEN': QA_VALIDATION_TOKEN,\n",
    "        'QA_VALIDATION_DATASET': QA_VALIDATION_DATASET,\n",
    "        'save_path': save_path,\n",
    "        'save_path_result': save_path_result, \n",
    "    }\n",
    "\n",
    "    ## this is a Dataset on which the RAGAs metrics can be applied\n",
    "    result_dataset = testset_to_validation(save=True,**config_2)\n",
    "\n",
    "    ## get ragas metrics\n",
    "    resulted_metrics = evaluate(\n",
    "        result_dataset,\n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            # faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_recall,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    chunking_configuration_results.append({'configuration': index_name, 'answer_relevancy': resulted_metrics['answer_relevancy'], 'context_precision': resulted_metrics['context_precision'], 'context_recall': resulted_metrics['context_recall']})\n",
    "\n",
    "    ## save individual results\n",
    "\n",
    "    resulted_metrics.to_pandas().to_csv(f'../data/chunking_configurations/{index_name}_results.csv',index=False)\n",
    "\n",
    "\n",
    "## save the results\n",
    "df = pd.DataFrame(chunking_configuration_results,columns=['configuration', 'answer_relevancy', 'context_precision', 'context_recall'])\n",
    "df.to_csv('../data/chunking_configurations/chunking_configuration_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 67)\n",
    "config_2 = {\n",
    "        'QA_VALIDATION_TOKEN': QA_VALIDATION_TOKEN,\n",
    "        'QA_VALIDATION_DATASET': QA_VALIDATION_DATASET,\n",
    "        'save_path': save_path,\n",
    "        'save_path_result': save_path_result, \n",
    "    }\n",
    "\n",
    "## this is a Dataset on which the RAGAs metrics can be applied\n",
    "result_dataset = testset_to_validation(save=True,**config_2)\n",
    "result_df = result_dataset.to_pandas()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get ragas metrics\n",
    "resulted_metrics = evaluate(\n",
    "    result_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "    ],\n",
    ")\n",
    "\n",
    "#faithfulness, PROBLEMATIC\n",
    "# context_precision,\n",
    "#         context_recall,\n",
    "#         answer_relevancy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## first define embeddings for the db\n",
    "\n",
    "\n",
    "## define what index to use and instantiate the vector store\n",
    "\n",
    "index_name = 'pubmedbert-sentence-transformer-400'\n",
    "\n",
    "elastic_vector_search = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    ")\n",
    "\n",
    "## define the LLM model to use | later this can be overwritten by the user\n",
    "llm = prepare_llm(HUGGINGFACE_TOKEN,model_id=model_id,use_openai=True)\n",
    "\n",
    "## create configuration for the run_config function\n",
    "save_path = '../data/rag_validation_answers_400.csv'\n",
    "\n",
    "config_1 = {\n",
    "    \"index_name\": index_name,\n",
    "    'evaluation_dataset_path': QA_VALIDATION_DATASET,\n",
    "    'HUGGINGFACE_TOKEN': HUGGINGFACE_TOKEN,\n",
    "    'HUGGINGFACE_DATASET_NAME': HUGGINGFACE_DATASET_NAME,\n",
    "    'llm': llm,\n",
    "    'QA_VALIDATION_TOKEN': QA_VALIDATION_TOKEN,\n",
    "    'save_path': save_path,\n",
    "    'max_retrieved_docs': 3\n",
    "}\n",
    "\n",
    "## this will save the results under the given path as a csv file\n",
    "## the file will contain the question and the result for each question in the validation dataset (questions generated with RAGas from the new dataset)\n",
    "## takes about 20-30 mins on T4 GPU\n",
    "answers = run_config(elastic_vector_search=elastic_vector_search,\n",
    "                     use_ensemble_retriever=False,\n",
    "                     verbose=True,\n",
    "                     config_name='new_dataset_400',\n",
    "                     save=True,\n",
    "                     **config_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f455066b8274210a6db0e838f826731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.8942793135767543,\n",
      " 'context_precision': 0.9253731342358208,\n",
      " 'context_recall': 0.9253731343283582,\n",
      " 'faithfulness': 0.825542328042328}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_2 = {\n",
    "    'QA_VALIDATION_TOKEN': QA_VALIDATION_TOKEN,\n",
    "    'QA_VALIDATION_DATASET': QA_VALIDATION_DATASET,\n",
    "    'save_path': save_path,\n",
    "    'save_path_result': '../data/validation_400_gpt_3-5-turbo.csv' \n",
    "}\n",
    "\n",
    "## this is a Dataset on which the RAGAs metrics can be applied\n",
    "result_dataset = testset_to_validation(save=True,**config_2)\n",
    "\n",
    "## get ragas metrics\n",
    "resulted_metrics = evaluate(\n",
    "    result_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "pprint(resulted_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8942793135767543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulted_metrics['answer_relevancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priot\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228519f811f44951b53a39899c0fcf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/69698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "\n",
    "loader = HuggingFaceDatasetLoader(\"MaraEliana/pubmed-abstracts\",use_auth_token=\"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\",page_content_column='abstract')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is the role of artificial intelligence in nephrology?\"\n",
    "# results = elastic_vector_search.similarity_search(query,k=50)\n",
    "\n",
    "\n",
    "# titles_elastic = [res.metadata[\"Title\"] for res in results]\n",
    "# for res in results:\n",
    "#     print(res.metadata['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Mara\n",
    "\n",
    "Using Ollama generate a bigger validation dataset of 5000 items (make TEST_SET_SIZE 5000).\n",
    "Change ChatOpenAI with the llama model (line 15/16)\n",
    "Save the resulting csv locally and send it to me so I can upload it to huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas \n",
    "from ragas.testset import TestsetGenerator\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from ragas.llms import LangchainLLM\n",
    "import random\n",
    "#https://docs.ragas.io/en/latest/howtos/customisations/llms.html\n",
    "\n",
    "sub_data = random.sample(data, TEST_SET_SIZE)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY)\n",
    "\n",
    "# Add custom llms and embeddings\n",
    "generator_llm = LangchainLLM(llm=ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY))\n",
    "critic_llm = LangchainLLM(llm=ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY)) ## should be gpt-4 but we dont have access\n",
    "embeddings_model = embeddings\n",
    "\n",
    "# Change resulting question type distribution\n",
    "testset_distribution = {\n",
    "    \"simple\": 0.25,\n",
    "    \"reasoning\": 0.25,\n",
    "    \"multi_context\": 0.25,\n",
    "    \"conditional\": 0.25,\n",
    "}\n",
    "\n",
    "# percentage of conversational question\n",
    "chat_qa = 0.1\n",
    "\n",
    "\n",
    "test_generator = TestsetGenerator(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings_model=embeddings_model,\n",
    "    testset_distribution=testset_distribution,\n",
    "    chat_qa=chat_qa,\n",
    ")\n",
    "\n",
    "testset = test_generator.generate(sub_data, test_size=TEST_SET_SIZE) ## why second parameter is 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv('testset.csv',index=False)\n",
    "\n",
    "# index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# pprint(test_df.iloc[index]['question'])\n",
    "\n",
    "# ## this is the answer\n",
    "# pprint(test_df.iloc[index]['ground_truth'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## relevant contexts split by \\n\n",
    "# pprint(test_df.iloc[index]['ground_truth_context'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
