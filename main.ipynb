{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from opensearch_utils import *\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "HUGGINGFACE_TOKEN = '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'\n",
    "HUGGINGFACE_USERNAME = 'prio7777777'\n",
    "HUGGINGFACE_DATASET_NAME = 'prio7777777/pubmed-demo'\n",
    "vectored_data_path = os.path.join(os.getcwd(),\"pubmed_demo_data.pkl\")\n",
    "\n",
    "connection_settings = {\n",
    "    'DB_USERNAME': 'admin',\n",
    "    'DB_PASSWORD': 'admin',\n",
    "    'DB_HOSTNAME': 'localhost',\n",
    "    'DB_PORT': '9200',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHyperparams to try:\\n\\n1. number of fragments\\n2. splitting strategy\\n3. model for embeddings\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Hyperparams to try:\n",
    "\n",
    "1. number of fragments / sentence fragmentation\n",
    "2. splitting strategy\n",
    "3. model for embeddings\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.25-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/site-packages (from langchain) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.9 (from langchain)\n",
      "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
      "  Downloading langchain_core-0.1.10-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
      "  Downloading langsmith-0.0.80-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.11/site-packages (from sentence-transformers) (0.20.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.2,>=0.1.7->langchain)\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.11-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langchain_core-0.1.10-py3-none-any.whl (216 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.80-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.25-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: tenacity, sniffio, mypy-extensions, marshmallow, jsonpointer, greenlet, typing-inspect, SQLAlchemy, jsonpatch, anyio, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.25 anyio-4.2.0 dataclasses-json-0.6.3 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.0 langchain-community-0.0.11 langchain-core-0.1.10 langsmith-0.0.80 marshmallow-3.20.2 mypy-extensions-1.0.0 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 35.9kB/s]\n",
      "config.json: 100%|██████████| 385/385 [00:00<00:00, 1.16MB/s]\n",
      "vocab.txt: 100%|██████████| 225k/225k [00:00<00:00, 1.20MB/s]\n",
      ".gitattributes: 100%|██████████| 690/690 [00:00<00:00, 1.66MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 524kB/s]\n",
      "README.md: 100%|██████████| 3.69k/3.69k [00:00<00:00, 10.7MB/s]\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 1.73MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 215kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:08<00:00, 11.2MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 345kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 398kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.60MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 766kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.17MB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 561kB/s]\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain sentence-transformers\n",
    "%pip install --upgrade transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "embed_model_id = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 95.0/95.0 [00:00<00:00, 307kB/s]\n",
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "Downloading data: 100%|██████████| 50.8M/50.8M [00:07<00:00, 6.45MB/s]\n",
      "Generating train split: 32584 examples [00:00, 46552.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average title length in tokens: 13.918303461821752\n",
      "Average abstract length in tokens: 220.59176282838203\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "if not os.path.exists(vectored_data_path):\n",
    "    dataset = load_dataset(HUGGINGFACE_DATASET_NAME,token=HUGGINGFACE_TOKEN)\n",
    "    ## statistics about the dataset\n",
    "    print(\"Average title length in tokens:\", sum(len(doc['Title'].split()) for doc in dataset['train']) / len(dataset['train']))\n",
    "    print(\"Average abstract length in tokens:\", sum(len(doc['Abstract'].split()) for doc in dataset['train']) / len(dataset['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to connect...\n",
      "Connected to OpenSearch {'name': 'opensearch-node1', 'cluster_name': 'opensearch-cluster', 'cluster_uuid': 'vrxH17fESUqSDCdLzzbWxQ', 'version': {'distribution': 'opensearch', 'number': '2.11.0', 'build_type': 'tar', 'build_hash': '4dcad6dd1fd45b6bd91f041a041829c8687278fa', 'build_date': '2023-10-13T02:55:55.511945994Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.10.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'The OpenSearch Project: https://opensearch.org/'}\n",
      "Creating index...\n",
      "Successfully created index\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database_connection = opensearch_connection('pubmed-index',connection_settings=connection_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\priot/.cache\\torch\\sentence_transformers\\microsoft_BiomedNLP-BiomedBERT-base-uncased-abstract. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# import SentenceTransformer and SentenceTransformersTokenTextSplitter classes\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "# create a SentenceTransformersTokenTextSplitter object\n",
    "splitter = SentenceTransformersTokenTextSplitter(\n",
    "    model_name=embed_model_id,  # specify the model used for tokenization\n",
    "    chunk_overlap=10,  # set the overlap between consecutive text chunks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectored_data = []\n",
    "if not os.path.exists(vectored_data_path):\n",
    "\n",
    "    for item in tqdm(dataset['train']):\n",
    "        title = item['Title']\n",
    "        abstract = item['Abstract'].replace(\"\\n\",\" \")\n",
    "\n",
    "        chunks = splitter.split_text(text=abstract)  # split the text into chunks\n",
    "\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            metadata = {\n",
    "                \"title\": title,\n",
    "                \"chunk_id\": j,\n",
    "                \"chunk_text\": chunk,\n",
    "            }\n",
    "\n",
    "            embedding = model.encode(chunk).tolist()\n",
    "\n",
    "            ##TODO: create unique identifier\n",
    "            \n",
    "            vectored_data.append((metadata, embedding))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to store the list\n",
    "def store_list(data, filename):\n",
    "  \"\"\"\n",
    "  Stores a list of tuples containing (id, embedding, metadata) to a file.\n",
    "\n",
    "  Args:\n",
    "      data: A list of tuples containing (id, embedding, metadata).\n",
    "      filename: The filename to store the data.\n",
    "  \"\"\"\n",
    "  with open(filename, \"wb\") as f:\n",
    "      # use pickle to serialize the data\n",
    "      import pickle\n",
    "      pickle.dump(data, f)\n",
    "\n",
    "\n",
    "# define a function to read the list\n",
    "def read_list(filename):\n",
    "  \"\"\"\n",
    "  Reads a list of tuples containing (embedding, metadata) from a file.\n",
    "\n",
    "  Args:\n",
    "      filename: The filename to read the data from.\n",
    "\n",
    "  Returns:\n",
    "      A list of tuples containing (id, embedding, metadata).\n",
    "  \"\"\"\n",
    "  with open(filename, \"rb\") as f:\n",
    "      # Use pickle to deserialize the data\n",
    "      import pickle\n",
    "      data = pickle.load(f)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(vectored_data_path):\n",
    "    store_list(vectored_data, \"pubmed_demo_data.pkl\")\n",
    "\n",
    "vectored_data = read_list(\"pubmed_demo_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32838, 384)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert embedding to numpy array\n",
    "import numpy as np\n",
    "embeddings = np.array([item[1] for item in vectored_data])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving articles to database: 100%|██████████| 32838/32838 [1:15:18<00:00,  7.27it/s]     \n"
     ]
    }
   ],
   "source": [
    "# loadArticlesVector(database_connection,vectored_data,'pubmed-index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8139,  0.5572,  0.9070, -0.0289])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### sanity STS check\n",
    "\n",
    "query = \"The algorithm named GasMIL was established and demonstrated encouraging performance in diagnosing IM AUC 0884\"\n",
    "\n",
    "documents = ['GasMIL proved good performance in diagnosing AUC 0884',\n",
    "             'The algorithm showed really interesting results for diagnosing purposes',\n",
    "             'GasMIL is a new algorithm for diagnosing IM AUC 0884',\n",
    "             'The dog is walking out in the park']\n",
    "\n",
    "# encode the query and the documents\n",
    "query_embedding = model.encode(query)\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "# compute the cosine similarity scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "cos_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['What is CV used for in medicine?']\n",
    "query_vector = model.encode(query)\n",
    "query_embedding = query_vector.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the OpenSearch search body\n",
    "body = {\n",
    "    # **Query:** match all documents and score them based on a custom script\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            # match all documents\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            },\n",
    "            # define a script to calculate the score\n",
    "            \"script\": {\n",
    "                # since cosine similarity ranges between -1 and 1 and\n",
    "                # opensearch is not able to process negative cosine similarity score\n",
    "                # therefore +1.0 is added\n",
    "                \"source\": \"cosineSimilarity(params.queryVector, doc['vector']) + 1.0\",\n",
    "                # pass the query vector as a parameter to the script\n",
    "                \"params\": {\n",
    "                    \"queryVector\": query_embedding\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # filter results with a minimum score of 1.45\n",
    "    \"min_score\": 1.45\n",
    "}\n",
    "\n",
    "# set the maximum number of results to retrieve\n",
    "size = 1000\n",
    "\n",
    "# perform the search with a 120-second timeout\n",
    "aux_results = database_connection.search(\n",
    "    index='pubmed-index',\n",
    "    body=body,\n",
    "    size=size,\n",
    "    request_timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "treatments and considerably reducing the mortality of cardiovascular diseases cvds\n",
      "Score: 1.6197655\n",
      "Title: Machine learning based hybrid anomaly detection technique for automatic diagnosis of cardiovascular diseases using cardiac sympathetic nerve activity and electrocardiogram\n",
      "----------\n",
      "cardiovascular disease cvd is a major global health concern several therapeutic strategies for cvds are available such as medicine cardiac assist devices and heart transplantation however they are insufficient for the treatment of severe cvd to develop novel innovative treatment approaches for cvds it is imperative to understand the underlying pathophysiology and to undertake basic research on this facet the generation of induced pluripotent stem ips cells has opened avenues for developing new strategies for disease analysis and drug development this technology has made it possible to obtain pluripotent stem cells from patients with genetic disorders model the disease in a dish and use such cells for future regeneration therapy meanwhile artificial intelligence ai which is widely used for big data analysis in basic research has potential in various applications in medicine new tools such as ips cells and ai can provide much needed novel insights into cvds this review focuses on the recent progress in cardiovascular research using these new technologies\n",
      "Score: 1.5946674\n",
      "Title: Recent Technological Innovations to Promote Cardiovascular Research\n",
      "----------\n",
      "the search for new strategies for better understanding cardiovascular cv disease is a constant one spanning multitudinous types of observations and studies a comprehensive characterization of each disease state and its biomolecular underpinnings relies upon insights gleaned from extensive information collection of various types of data researchers and clinicians in cv biomedicine repeatedly face questions regarding which types of data may best answer their questions how to integrate information from multiple datasets of various types and how to adapt emerging advances in machine learning and or artificial intelligence to their needs in data processing frequently lauded as a field with great practical and translational potential the interface between biomedical informatics and cv medicine is challenged with staggeringly massive datasets successful application of computational approaches to decode these complex and gigantic amounts of information becomes an essential step toward realizing the desired benefits in this review we examine recent efforts to adapt informatics strategies to cv biomedical research automated information extraction and unification of multifaceted omics data we discuss how and why this interdisciplinary space of cv informatics is particularly relevant to and supportive of current experimental and clinical research we describe in detail how open data sources and methods can drive discovery while demanding few initial resources an advantage afforded by widespread availability of cloud computing driven platforms subsequently we provide examples of how interoperable computational systems facilitate exploration of data from multiple sources including both consistently formatted structured data and unstructured data taken together these approaches for achieving data harmony enable molecular phenotyping of cv diseases and unification of cv knowledge\n",
      "Score: 1.5770293\n",
      "Title: Cardiovascular informatics building a bridge to data harmony\n",
      "----------\n",
      "cardiovascular diseases cvds aredisorders of the heart and blood vessels and are a major cause of disability and premature death worldwide individuals at higher risk of developing cvd must be noticed at an early stage to prevent premature deaths advances in the field of computational intelligence together with the vast amount of data produced daily in clinical settings have made it possible to create recognition systems capable of identifying hidden patterns and useful information this paper focuses on the application of data mining techniques dmts to clinical data collected during the medical examination in an attempt to predict whether or not an individual has a cvd to this end the crossindustry standard process for data mining crisp dm methodology was followed in which five classifiers were applied namely dt optimized dt ri rf and dl the models were mainly developed using the rapidminer software with the assist of the weka tool and were analyzed based on accuracy precision sensitivity and specificity the results obtained were considered promising on the basis of the research for effective means of diagnosing cvd with the best model being optimized dt which achieved the highest values for all the evaluation metrics 73 54 75 82 68 89 78 16 and 0 788 for accuracy precision sensitivity specificity and auc respectively\n",
      "Score: 1.5712017\n",
      "Title: Data Mining for Cardiovascular Disease Prediction\n",
      "----------\n",
      "purpose of review cardiovascular disease cvd and stroke risk assessment have been largely based on the success of traditional statistically derived risk calculators such as pooled cohort risk score or framingham risk score however over the last decade automated computational paradigms such as machine learning ml and deep learning dl techniques have penetrated into a variety of medical domains including cvd stroke risk assessment this review is mainly focused on the changing trends in cvd stroke risk assessment and its stratification from statistical based models to ml based paradigms using non invasive carotid ultrasonography recent findings in this review ml based strategies are categorized into two types non image or conventional ml based and image based or integrated ml based the success of conventional non image based ml based algorithms lies in the different data driven patterns or features which are used to train the ml systems typically these features are the patients demographics serum biomarkers and multiple clinical parameters the integrated image based ml based algorithms integrate the features derived from the ultrasound scans of the arterial walls such as morphological measurements with conventional risk factors in ml frameworks even though the review covers ml based system designs for carotid and coronary ultrasonography the main focus of the review is on cvd stroke risk scores based on carotid ultrasound there are two key conclusions from this review i fusion of image based features with conventional cardiovascular risk factors can lead to more accurate cvd stroke risk stratification ii the ability to handle multiple sources of information in big data framework using artificial intelligence based paradigms such as ml and dl is likely to be the future in preventive cvd stroke risk assessment\n",
      "Score: 1.5526199\n",
      "Title: A Special Report on Changing Trends in Preventive Stroke Cardiovascular Risk Assessment Via B Mode Ultrasonography\n",
      "----------\n",
      "aims to provide an overview of the role of cardiovascular cv imaging in facilitating and advancing the field of precision medicine in cv disease methods and results non invasive cv imaging is essential to accurately and efficiently phenotype patients with heart disease including coronary artery disease cad and heart failure hf various modalities such as echocardiography nuclear cardiology cardiac computed tomography ct cardiovascular magnetic resonance cmr and invasive coronary angiography and in some cases a combination can be required to provide sufficient information for diagnosis and management taking cad as an example imaging is essential for the detection and functional assessment of coronary stenoses as well as for the quantification of cardiac function and ischaemic myocardial damage furthermore imaging may detect and quantify coronary atherosclerosis potentially identify plaques at increased risk of rupture and guide coronary interventions in patients with hf imaging helps identify specific aetiologies quantify damage and assess its impact on cardiac function imaging plays a central role in individualizing diagnosis and management and to determine the optimal treatment for each patient to increase the likelihood of response and improve patient outcomes conclusions advances in all imaging techniques continue to improve accuracy sensitivity and standardization of functional and prognostic assessments and identify established and novel therapeutic targets combining imaging with artificial intelligence machine learning and computer algorithms as well as with genomic transcriptomic proteomic and metabolomic approaches will become state of the art in the future to understand pathologies of cad and hf and in the development of new targeted therapies\n",
      "Score: 1.5513965\n",
      "Title: Non invasive imaging as the cornerstone of cardiovascular precision medicine\n",
      "----------\n",
      "background cardiovascular diseases cvds are difficult to diagnose early and have risk factors that are easy to overlook early prediction and personalization of treatment through the use of artificial intelligence ai may help clinicians and patients manage cvds more effectively however to apply ai approaches to cvds data it is necessary to establish and curate a specialized database based on electronic health records ehrs and include pre processed unstructured data methods to build a suitable database cardionet for cvds that can utilize ai technology contributing to the overall care of patients with cvds first we collected the anonymized records of 748 474 patients who had visited the asan medical center amc or ulsan university hospital uuh because of cvds second we set clinically plausible criteria to remove errors and duplication third we integrated unstructured data such as readings of medical examinations with structured data sourced from ehrs to create the cardionet we subsequently performed natural language processing to structuralize the significant variables associated with cvds because most results of the principal cvd related medical examinations are free text readings additionally to ensure interoperability for convergent multi center research we standardized the data using several codes that correspond to the common data model finally we created the descriptive table i e dictionary of the cardionet to simplify access and utilization of data for clinicians and engineers and continuously validated the data to ensure reliability results cardionet is a comprehensive database that can serve as a training set for ai models and assist in all aspects of clinical management of cvds it comprises information extracted from ehrs and results of readings of cvd related digital tests it consists of 27 tables a code master table and a descriptive table conclusions cardionet database specialized in cvds was established with continuing data collection we are actively supporting multi center research which may require further data processing depending on the subject of the study cardionet will serve as the fundamental database for future cvd related research projects\n",
      "Score: 1.541548\n",
      "Title: CardioNet a manually curated database for artificial intelligence based research on cardiovascular diseases\n",
      "----------\n",
      "recent findings cardiovascular disease cvd is the leading cause of mortality and poses challenges for healthcare providers globally risk based approaches for the management of cvd are becoming popular for recommending treatment plans for asymptomatic individuals several conventional predictive cvd risk models based do not provide an accurate cvd risk assessment for patients with different baseline risk profiles artificial intelligence ai algorithms have changed the landscape of cvd risk assessment and demonstrated a better performance when compared against conventional models mainly due to its ability to handle the input nonlinear variations further it has the flexibility to add risk factors derived from medical imaging modalities that image the morphology of the plaque the integration of noninvasive carotid ultrasound image based phenotypes with conventional risk factors in the ai framework has further provided stronger power for cvd risk prediction so called integrated predictive cvd risk models purpose of the review the objective of this review is i to understand several aspects in the development of predictive cvd risk models ii to explore current conventional predictive risk models and their successes and challenges and iii to refine the search for predictive cvd risk models using noninvasive carotid ultrasound as an exemplar in the artificial intelligence based framework conclusion conventional predictive cvd risk models are suboptimal and could be improved this review examines the potential to include more noninvasive image based phenotypes in the cvd risk assessment using powerful ai based strategies\n",
      "Score: 1.5355186\n",
      "Title: Artificial intelligence framework for predictive cardiovascular and stroke risk assessment models A narrative review of integrated approaches using carotid ultrasound\n",
      "----------\n",
      "cardiovascular disease cvd is the most common cause of morbidity and mortality worldwide and early accurate diagnosis is the key point for improving and optimizing the prognosis of cvd recent progress in artificial intelligence ai especially machine learning ml technology makes it possible to predict cvd in this review we first briefly introduced the overview development of artificial intelligence then we summarized some ml applications in cardiovascular diseases including ml based models to directly predict cvd based on risk factors or medical imaging findings and the ml based hemodynamics with vascular geometries equations and methods for indirect assessment of cvd we also discussed case studies where ml could be used as the surrogate for computational fluid dynamics in data driven models and physics driven models ml models could be a surrogate for computational fluid dynamics accelerate the process of disease prediction and reduce manual intervention lastly we briefly summarized the research difficulties and prospected the future development of ai technology in cardiovascular diseases\n",
      "Score: 1.5191939\n",
      "Title: Interplay between Artificial Intelligence and Biomechanics Modeling in the Cardiovascular Disease Prediction\n",
      "----------\n",
      "cardiac imaging plays an important role in the diagnosis of cardiovascular disease cvd until now its role has been limited to visual and quantitative assessment of cardiac structure and function however with the advent of big data and machine learning new opportunities are emerging to build artificial intelligence tools that will directly assist the clinician in the diagnosis of cvds this paper presents a thorough review of recent works in this field and provide the reader with a detailed presentation of the machine learning methods that can be further exploited to enable more automated precise and early diagnosis of most cvds\n",
      "Score: 1.5181385\n",
      "Title: Image Based Cardiac Diagnosis With Machine Learning A Review\n",
      "----------\n",
      "cardiovascular disease cvd is the world s leading cause of mortality there is significant interest in using artificial intelligence ai to analyse data from novel sensors such as wearables to provide an earlier and more accurate prediction and diagnosis of heart disease digital health technologies that fuse ai and sensing devices may help disease prevention and reduce the substantial morbidity and mortality caused by cvd worldwide in this review we identify and describe recent developments in the application of digital health for cvd focusing on ai approaches for cvd detection diagnosis and prediction through ai models driven by data collected from wearables we summarise the literature on the use of wearables and ai in cardiovascular disease diagnosis followed by a detailed description of the dominant ai approaches applied for modelling and prediction using data acquired from sensors such as wearables we discuss the ai algorithms and models and clinical applications and find that ai and machine learning based approaches are superior to traditional or conventional statistical methods for predicting cardiovascular events however further studies evaluating the applicability of such algorithms in the real world are needed in addition improvements in wearable device data accuracy and better management of their application are required lastly we discuss the challenges that the introduction of such technologies into routine healthcare may face\n",
      "Score: 1.5176425\n",
      "Title: Applying Artificial Intelligence to Wearable Sensor Data to Diagnose and Predict Cardiovascular Disease A Review\n",
      "----------\n",
      "cardiovascular disease cvd is one among the main factors for the increase in mortality rate worldwide the analysis and prediction of this disease is yet a highly formidable task in medical data analysis recent advancements in technology such as big data artificial intelligence and the need for automated models have paved the way for developing a more reliable and efficient model for predicting heart disease several researches have been carried out in predicting heart diseases but the focus on choosing the important attributes that play a significant role in predicting cvd is inadequate hence the choice of right features for the classification and the diagnosis of the heart disease is important the core aim of this work is to identify and select the important features and machine learning methodologies that can enhance the prediction capability of the classification models for accurately predicting cvd the results show that the proposed enhanced evolutionary feature selection with the hybrid ensemble model outperforms the existing approaches in terms of precision recall and accuracy the experimental outcomes show that the proposed approach attains the maximum classification accuracy of 93 65 for statlog dataset 82 81 for spectf dataset and 84 95 for coronary heart disease dataset the proposed classification model performance is demonstrated using roc curve against state of the art methods in machine learning\n",
      "Score: 1.5146935\n",
      "Title: Enhanced Evolutionary Feature Selection and Ensemble Method for Cardiovascular Disease Prediction\n",
      "----------\n",
      "introduces a novel and informative method which could help create recommendation list of tcm prescriptions for the treatment of other diseases\n",
      "Score: 1.5141158\n",
      "Title: Evaluating the Traditional Chinese Medicine TCM Officially Recommended in China for COVID 19 Using Ontology Based Side Effect Prediction Framework OSPF and Deep Learning\n",
      "----------\n",
      "cardiovascular disease cvd is the number one leading cause for human mortality besides genetics and environmental factors in recent years gut microbiota has emerged as a new factor influencing cvd although cause effect relationships are not clearly established the reported associations between alterations in gut microbiota and cvd are prominent therefore we hypothesized that machine learning ml could be used for gut microbiome based diagnostic screening of cvd to test our hypothesis fecal 16s ribosomal rna sequencing data of 478 cvd and 473 non cvd human subjects collected through the american gut project were analyzed using 5 supervised ml algorithms including random forest support vector machine decision tree elastic net and neural networks thirty nine differential bacterial taxa were identified between the cvd and non cvd groups ml modeling using these taxonomic features achieved a testing area under the receiver operating characteristic curve 0 0 perfect antidiscrimination 0 5 random guessing 1 0 perfect discrimination of 0 58 random forest and neural networks next the ml models were trained with the top 500 high variance features of operational taxonomic units instead of bacterial taxa and an improved testing area under the receiver operating characteristic curves of 0 65 random forest was achieved further by limiting the selection to only the top 25 highly contributing operational taxonomic unit features the area under the receiver operating characteristic curves was further significantly enhanced to 0 70 overall our study is the first to identify dysbiosis of gut microbiota in cvd patients as a group and apply this knowledge to develop a gut microbiome based ml approach for diagnostic screening of cvd\n",
      "Score: 1.5113001\n",
      "Title: Machine Learning Strategy for Gut Microbiome Based Diagnostic Screening of Cardiovascular Disease\n",
      "----------\n",
      "the advent of advances in machine learning ml based techniques has popularized wide applications of artificial intelligence ai in various fields ranging from robotics to medicine in recent years there has been a surge in the application of ai to research in cardiovascular medicine which is largely driven by the availability of large scale clinical and multi omics datasets such applications are providing a new perspective for a better understanding of cardiovascular disease cvd which could be used to develop novel diagnostic and therapeutic strategies for example studies have shown that ml has a substantial potential for early diagnosis of different types of cvd prediction of adverse disease outcomes such as heart failure and development of newer and personalized treatments in this article we provide an overview and discuss the current status of a wide range of ai applications including machine learning reinforcement learning and deep learning in cardiovascular medicine 2021 american physiological society compr physiol 11 1 12 2021\n",
      "Score: 1.5038223\n",
      "Title: Application of Artificial Intelligence in Cardiovascular Medicine\n",
      "----------\n",
      "purpose of review to summarize selected late breaking science on cardiovascular cv disease prevention presented at the 2023 american college of cardiology acc conference recent findings the clear outcomes randomized control trial rct compared bempedoic acid to placebo in patients at high risk of cardiovascular disease cvd or prevalent cvd and statin intolerance for cv outcomes the yellow iii was a single arm study that evaluated the effect of evolocumab on coronary plaque characteristics in patients with stable coronary artery disease cad a cohort evaluated the association between a self reported low carbohydrate high fat ketogenic diet and serum lipid levels as compared to a standard diet the loadstar trial compared cv outcomes with targeted low density lipoprotein cholesterol ldl c approach vs high intensity statin in patients with cad the pcds statin cluster randomized trial compared the effectiveness of an electronic reminder to the clinician on a high intensity statin use among patients with a history of ascvd as compared to no reminder a prospective cohort study compared the extent of coronary atherosclerosis among lifelong endurance athletes and healthy non athletes a causal artificial intelligence study combined polygenic risk scores with data from large cv prevention rcts to guide systolic blood pressure and ldl c reduction targets to reach average cv risk the access trial evaluated the impact of eliminating copayment for low income older adults in canada with chronic cv diseases on composite cv outcomes a pooled analysis of 3 large rcts evaluated the association between residual inflammatory risk and cv outcomes as compared to residual elevated cholesterol risk in patients receiving statin therapy a phase 2b rct compared the efficacy of an oral pcsk9i mk 0616 in reducing ldl c as compared to a placebo the late breaking clinical science presented at the 2023 conference of the acc paves the way for an evidence based alternative to statin therapy and provides data on several common clinical scenarios encountered in daily practice\n",
      "Score: 1.5026855\n",
      "Title: Highlights of Cardiovascular Disease Prevention Studies Presented at the 2023 American College of Cardiology Conference\n",
      "----------\n",
      "an extensive in depth study of cardiovascular risk factors cvrf seems to be of crucial importance in the research of cardiovascular disease cvd in order to prevent or reduce the chance of developing or dying from cvd the main focus of data analysis is on the use of models able to discover and understand the relationships between different cvrf in this paper a report on applying bayesian network bn modeling to discover the relationships among thirteen relevant epidemiological features of heart age domain in order to analyze cardiovascular lost years cvly cardiovascular risk score cvrs and metabolic syndrome mets is presented furthermore the induced bn was used to make inference taking into account three reasoning patterns causal reasoning evidential reasoning and intercausal reasoning application of bn tools has led to discovery of several direct and indirect relationships between different cvrf the bn analysis showed several interesting results among them cvly was highly influenced by smoking being the group of men the one with highest risk in cvly mets was highly influence by physical activity pa being again the group of men the one with highest risk in mets and smoking did not show any influence bns produce an intuitive transparent graphical representation of the relationships between different cvrf the ability of bns to predict new scenarios when hypothetical information is introduced makes bn modeling an artificial intelligence ai tool of special interest in epidemiological studies as cvd is multifactorial the use of bns seems to be an adequate modeling tool\n",
      "Score: 1.5003066\n",
      "Title: Bayesian network modeling A case study of an epidemiologic system analysis of cardiovascular risk\n",
      "----------\n",
      "image data has grown exponentially as systems have increased their ability to collect and store it unfortunately there are limits to human resources both in time and knowledge to fully interpret and manage that data computer vision cv has grown in popularity as a discipline for better understanding visual data computer vision has become a powerful tool for imaging analytics in orthopedic surgery allowing computers to evaluate large volumes of image data with greater nuance than previously possible nevertheless even with the growing number of uses in medicine literature on the fundamentals of cv and its implementation is mainly oriented toward computer scientists rather than clinicians rendering cv unapproachable for most orthopedic surgeons as a tool for clinical practice and research the purpose of this article is to summarize and review the fundamental concepts of cv application for the orthopedic surgeon and musculoskeletal researcher\n",
      "Score: 1.4934194\n",
      "Title: Educational Overview of the Concept and Application of Computer Vision in Arthroplasty\n",
      "----------\n",
      "motivation the early screening of cardiovascular diseases cvd can lead to effective treatment thus accurate and reliable atherosclerotic carotid wall detection and plaque measurements are crucial current measurement methods are time consuming and do not utilize the power of knowledge based paradigms such as artificial intelligence ai we present an ai based methodology for the joint automated detection and measurement of wall thickness and carotid plaque cp in the form of carotid intima media thickness cimt and total plaque area tpa a class of atheroedge system atheropoint ca usa method the novel system consists of two stages and each stage comprises an independent deep learning dl model in stage i the first dl model segregates the common carotid artery cca patches from ultrasound us images into the rectangular wall and non wall patches the characterized wall patches are integrated to form the region of interest roi which is then fed into stage ii in stage ii the second dl model segments the far wall region lumen intima li and media adventitial ma boundaries are then extracted from the wall region which is then used for cimt and pa measurement results using the database of 250 carotid scans the cimt error using the ai model is 0 0935 0 0637 mm which is lower than those of all previous methods the pa error is found to be 2 7939 2 3702 mm2 the system s correlation coefficient cc between ai and ground truth gt values for cimt is 0 99 p 0 0001 which is higher compared with the cc of 0 96 p 0 0001 shown by the earlier dl method the cc for pa between ai and gt values is 0 89 p 0 0001 conclusion a novel ai based strategy was applied to carotid us images for the joint detection of carotid wall thickness cwt and plaque area pa followed by cimt and pa measurement this ai based strategy shows improved performance using the patch technique compared with previous methods using full carotid scans\n",
      "Score: 1.4890538\n",
      "Title: Two stage artificial intelligence model for jointly measurement of atherosclerotic wall thickness and plaque burden in carotid ultrasound A screening tool for cardiovascular stroke risk assessment\n",
      "----------\n",
      "background acute ischemic stroke ais is an immediate emergency whose management is becoming more and more personalized while facing a limited number of neurologists with high expertise clinical decision support systems cdss are digital tools leveraging information and artificial intelligence technologies here we present the strokecopilot project a cdss for the management of the acute phase of ais it has been designed to support the evidence based medicine reasoning of neurologists regarding the indications of intravenous thrombolysis ivt and endovascular treatments et methods reference populations were manually extracted from the field s main guidelines and randomized clinical trials rct their characteristics were harmonized in a computerized reference database we developed a web application whose algorithm identifies the reference populations matching the patient s characteristics it returns the latter s outcomes in a graphical user interface gui whose design has been driven by real world practices results strokecopilot has been released at www digitalneurology net the reference database includes 25 reference populations from 2 guidelines and 15 rcts after a request the reference populations matching the patient characteristics are displayed with a summary and a meta analysis of their results the status regarding ivt and et indications are presented as in guidelines in literature or outside literature references the gui is updated to provide several levels of explanation strokecopilot may be updated as the literature evolves by loading a new version of the reference populations database conclusion strokecopilot is a literature based cdss developed to support neurologists in the management of the acute phase of ais\n",
      "Score: 1.4870026\n",
      "Title: Strokecopilot a literature based clinical decision support system for acute ischemic stroke treatment\n",
      "----------\n",
      "background the critical view of safety cvs was proposed in 1995 to prevent bile duct injury during laparoscopic cholecystectomy lc the achievement of cvs was evaluated subjectively this study aimed to develop an artificial intelligence ai system to evaluate cvs scores in lc materials and methods ai software was developed to evaluate the achievement of cvs using an algorithm for image classification based on a deep convolutional neural network short clips of hepatocystic triangle dissection were converted from 72 lc videos and 23 793 images were labeled for training data the learning models were examined using metrics commonly used in machine learning results the mean values of precision recall f measure specificity and overall accuracy for all the criteria of the best model were 0 971 0 737 0 832 0 966 and 0 834 respectively it took approximately 6fps to obtain scores for a single image conclusions using the ai system we successfully evaluated the achievement of the cvs criteria using still images and videos of hepatocystic triangle dissection in lc this encourages surgeons to be aware of cvs and is expected to improve surgical safety\n",
      "Score: 1.4867802\n",
      "Title: Development of an artificial intelligence system for real time intraoperative assessment of the Critical View of Safety in laparoscopic cholecystectomy\n",
      "----------\n",
      "there has been a tidal wave of recent interest in artificial intelligence ai machine learning and deep learning approaches in cardiovascular cv medicine in the era of modern medicine ai and electronic health records hold the promise to improve the understanding of disease conditions and bring a personalized approach to cv care the field of cv imaging cvi incorporating echocardiography cardiac computed tomography cardiac magnetic resonance imaging and nuclear imaging with sophisticated imaging techniques and high volumes of imaging data is primed to be at the forefront of the revolution in precision cardiology this review provides a contemporary overview of the cvi imaging applications of ai including a critique of the strengths and potential limitations of deep learning approaches\n",
      "Score: 1.4852397\n",
      "Title: Applications of artificial intelligence in multimodality cardiovascular imaging A state of the art review\n",
      "----------\n",
      "cardiovascular diseases cvds carry significant morbidity and mortality and are associated with substantial economic burden on healthcare systems around the world coronary artery disease as one disease entity under the cvds umbrella had a prevalence of 7 2 among adults in the united states and incurred a financial burden of 360 billion us dollars in the years 2016 2017 the introduction of artificial intelligence ai and machine learning over the last two decades has unlocked new dimensions in the field of cardiovascular medicine from automatic interpretations of heart rhythm disorders via smartwatches to assisting in complex decision making ai has quickly expanded its realms in medicine and has demonstrated itself as a promising tool in helping clinicians guide treatment decisions understanding complex genetic interactions and developing clinical risk prediction models advanced cardiac imaging and improving mortality outcomes are just a few areas where ai has been applied in the domain of coronary artery disease through this review we sought to summarize the advances in ai relating to coronary artery disease current limitations and future perspectives\n",
      "Score: 1.4850783\n",
      "Title: Current and Future Applications of Artificial Intelligence in Coronary Artery Disease\n",
      "----------\n",
      "effective cardiovascular disease cvd prevention relies on timely identification and intervention for individuals at risk conventional formula based techniques have been demonstrated to over or under predict the risk of cvd in the australian population this study assessed the ability of machine learning models to predict cvd mortality risk in the australian population and compare performance with the well established framingham model data is drawn from three australian cohort studies the north west adelaide health study nwahs the australian diabetes obesity and lifestyle study and the melbourne collaborative cohort study mccs four machine learning models for predicting 15 year cvd mortality risk were developed and compared to the 2008 framingham model machine learning models performed significantly better compared to the framingham model when applied to the three australian cohorts machine learning based models improved prediction by 2 7 to 5 2 across three australian cohorts in an aggregated cohort machine learning models improved prediction by up to 5 1 area under curve auc 0 852 95 ci 0 837 0 867 net reclassification improvement nri was up to 26 with machine learning models machine learning based models also showed improved performance when stratified by sex and diabetes status results suggest a potential for improving cvd risk prediction in the australian population using machine learning models\n",
      "Score: 1.4798914\n",
      "Title: Predicting Australian Adults at High Risk of Cardiovascular Disease Mortality Using Standard Risk Factors and Machine Learning\n",
      "----------\n",
      "the challenges associated with diagnosing and treating cardiovascular disease cvd stroke in rheumatoid arthritis ra arise from the delayed onset of symptoms existing clinical risk scores are inadequate in predicting cardiac events and conventional risk factors alone do not accurately classify many individuals at risk several cvd biomarkers consider the multiple pathways involved in the development of atherosclerosis which is the primary cause of cvd stroke in ra to enhance the accuracy of cvd stroke risk assessment in the ra framework a proposed approach involves combining genomic based biomarkers gbbm derived from plasma and or serum samples with innovative non invasive radiomic based biomarkers rbbm such as measurements of synovial fluid plaque area and plaque burden this review presents two hypotheses i rbbm and gbbm biomarkers exhibit a significant correlation and can precisely detect the severity of cvd stroke in ra patients ii artificial intelligence ai based preventive precision and personalized aip3 cvd stroke risk atheroedge model atheropoint ca usa that utilizes deep learning dl to accurately classify the risk of cvd stroke in ra framework the authors conducted a comprehensive search using the prisma technique identifying 153 studies that assessed the features biomarkers of rbbm and gbbm for cvd stroke the study demonstrates how dl models can be integrated into the atheroedge aip3 framework to determine the risk of cvd stroke in ra patients the findings of this review suggest that the combination of rbbm with gbbm introduces a new dimension to the assessment of cvd stroke risk in the ra framework synovial fluid levels that are higher than normal lead to an increase in the plaque burden additionally the review provides recommendations for novel unbiased and pruned dl algorithms that can predict cvd stroke risk within a ra framework that is preventive precise and personalized\n",
      "Score: 1.4791794\n",
      "Title: Artificial intelligence based preventive personalized and precision medicine for cardiovascular disease stroke risk assessment in rheumatoid arthritis patients a narrative review\n",
      "----------\n",
      "background atherosclerosis is the primary cause of the cardiovascular disease cvd several risk factors lead to atherosclerosis and altered nutrition is one among those nutrition has been ignored quite often in the process of cvd risk assessment altered nutrition along with carotid ultrasound imaging driven atherosclerotic plaque features can help in understanding and banishing the problems associated with the late diagnosis of cvd artificial intelligence ai is another promisingly adopted technology for cvd risk assessment and management therefore we hypothesize that the risk of atherosclerotic cvd can be accurately monitored using carotid ultrasound imaging predicted using ai based algorithms and reduced with the help of proper nutrition layout the review presents a pathophysiological link between nutrition and atherosclerosis by gaining a deep insight into the processes involved at each stage of plaque development after targeting the causes and finding out results by low cost user friendly ultrasound based arterial imaging it is important to i stratify the risks and ii monitor them by measuring plaque burden and computing risk score as part of the preventive framework artificial intelligence ai based strategies are used to provide efficient cvd risk assessments finally the review presents the role of ai for cvd risk assessment during covid 19 conclusions by studying the mechanism of low density lipoprotein formation saturated and trans fat and other dietary components that lead to plaque formation we demonstrate the use of cvd risk assessment due to nutrition and atherosclerosis disease formation during normal and covid times further nutrition if included as a part of the associated risk factors can benefit from atherosclerotic disease progression and its management using ai based cvd risk assessment\n",
      "Score: 1.4760292\n",
      "Title: Nutrition atherosclerosis arterial imaging cardiovascular risk stratification and manifestations in COVID 19 framework a narrative review\n",
      "----------\n",
      "network medicine can advance current medical practice by arising as response to the limitations of a reductionist approach focusing on cardiovascular cv diseases as a direct consequence of a single defect this molecular bioinformatic approach integrates heterogeneous omics data and artificial intelligence to identify a chain of perturbations involving key components of multiple molecular networks that are closely related in the human interactome the clinical view of the network based approach is greatly supported by the general law of molecular interconnection governing all biological complex systems recent advances in bioinformatics have culminated in numerous quantitative platforms able to identify cv disease modules underlying perturbations of the interactome this might provide novel insights in cv disease mechanisms as well as putative biomarkers and drug targets we describe the network based principles and discuss their application to classifying and treating common cv diseases we compare the strengths and weaknesses of molecular networks in comparison with the classical current reductionist approach and remark on the necessity for a two way approach connecting network medicine with large clinical trials to concretely translate novel insights from bench to bedside\n",
      "Score: 1.4736335\n",
      "Title: Strengths and Opportunities of Network Medicine in Cardiovascular Diseases\n",
      "----------\n",
      "timely and accurate detection of cardiovascular diseases cvds is critically important to minimize the risk of a myocardial infarction relations between factors of cvds are complex ill defined and nonlinear justifying the use of artificial intelligence tools these tools aid in predicting and classifying cvds in this article we propose a methodology using machine learning ml approaches to predict classify and improve the diagnostic accuracy of cvds including support vector regression svr multivariate adaptive regression splines the m5tree model and neural networks for the training process moreover adaptive neuro fuzzy and statistical approaches nearest neighbor naive bayes classifiers and adaptive neuro fuzzy inference system anfis are used to predict seventeen cvd risk factors mixed data transformation and classification methods are employed for categorical and continuous variables predicting cvd risk we compare our hybrid models and existing ml techniques on a cvd real dataset collected from a hospital a sensitivity analysis is performed to determine the influence and exhibit the essential variables with regard to cvds such as the patient s age cholesterol level and glucose level our results report that the proposed methodology outperformed well known statistical and ml approaches showing their versatility and utility in cvd classification our investigation indicates that the prediction accuracy of anfis for the training process is 96 56 followed by svr with 91 95 prediction accuracy our study includes a comprehensive comparison of results obtained for the mentioned methods\n",
      "Score: 1.4726615\n",
      "Title: Early Prediction in Classification of Cardiovascular Diseases with Machine Learning Neuro Fuzzy and Statistical Methods\n",
      "----------\n",
      "background the cardiovascular cv system is profoundly affected by thyroid hormones both hypo and hyperthyroidism can increase the risk of severe cv complications objective to assess the association of hyperthyroidism with major cv risk factors cvrfs and cv diseases cvds using a big data methodology with the savana manager platform material and methods this was an observational and retrospective study the data were obtained from the electronic medical records of the university hospital puerta de hierro majadahonda spain artificial intelligence techniques were used to extract the information from the electronic health records and savana manager 3 0 software was used for analysis results of a total of 540 939 patients studied 53 62 females mean age 42 2 8 7 years 5504 patients 1 02 69 9 women had a diagnosis of hyperthyroidism patients with this diagnosis had a significantly p 0 0001 higher frequency of cvrfs than that found in non hyperthyroid subjects the higher frequency of cvrfs in patients with hyperthyroidism was observed in both women and men and in patients younger and older than 65 years of age the total frequency of cvds was also significantly p 0 0001 higher in patients diagnosed with hyperthyroidism than that found in patients without this diagnosis the highest odds ratio values obtained were 6 40 4 27 9 61 for embolic stroke followed by 5 99 5 62 6 38 for atrial fibrillation the frequency of all cvds evaluated in patients with a diagnosis of hyperthyroidism was significantly higher in both women and men as well as in those younger and older than 65 years compared to subjects without this diagnosis a multivariate regression analysis showed that hyperthyroidism was significantly and independently associated with all the cvds evaluated except for embolic stroke conclusion the data from this hospital cohort suggest that there is a significant association between the diagnosis of hyperthyroidism and the main cvrfs and cvds in our population regardless of the age and gender of the patients our study in addition to confirming this association provides useful information for understanding the applicability of artificial intelligence techniques to real world data and information\n",
      "Score: 1.4720206\n",
      "Title: Hyperthyroidism and cardiovascular disease an association study using big data analytics\n",
      "----------\n",
      "1 purpose this study proposes a method of prediction of cardiovascular diseases cvds that can develop within ten years in patients with sleep disordered breathing sdb 2 methods for the design and evaluation of the algorithm the sleep heart health study shhs data from the 3367 participants were divided into a training set validation set and test set in the ratio of 5 3 2 from the data during a baseline period when patients did not have any cvd we extracted 18 features from electrography ecg based on signal processing methods 30 ecg features based on artificial intelligence ai ten clinical risk factors for cvd we trained the model and evaluated it by using cvd outcomes result monitored in follow ups the optimal feature vectors were selected through statistical analysis and support vector machine recursive feature elimination svm rfe of the extracted feature vectors features based on ai a novel proposal from this study showed excellent performance out of all selected feature vectors in addition new parameters based on ai were possibly meaningful predictors for cvd when used in addition to the predictors for cvd that are already known the selected features were used as inputs to the prediction model based on svm for cvd determining the development of cvd free coronary heart disease chd heart failure hf or stroke within ten years 3 results as a result the respective recall and precision values were 82 9 and 87 5 for cvd free 71 9 and 63 8 for cvd 57 2 and 55 4 for chd 52 6 and 40 8 for hf 52 4 and 44 6 for stroke the f1 score between cvd and cvd free was 76 5 and it was 59 1 in class four 4 conclusion in conclusion our results confirm the excellence of the prediction model for cvd in patients with sdb and verify the possibility of prediction within ten years of the cvds that may occur in patients with sdb\n",
      "Score: 1.4693346\n",
      "Title: A Prediction Model of Incident Cardiovascular Disease in Patients with Sleep Disordered Breathing\n",
      "----------\n",
      "objective cardiovascular disease cvd is a major healthcare challenge and therefore early risk assessment is vital previous assessment techniques use either conventional cvd risk calculators ccvrc or machine learning ml paradigms these techniques are ad hoc unreliable not fully automated and have variabilities we therefore introduce atheroedge mcdlai ae3 0dl windows based platform using multiclass deep learning dl system methods data was collected on 500 patients having both carotid ultrasound and corresponding coronary angiography scores cas measured as stenosis in coronary arteries and considered as the gold standard a total of 39 covariates were used clubbed into three clusters namely i office based age gender body mass index smoker hypertension systolic blood pressure and diastolic blood pressure ii laboratory based hyperlipidemia hemoglobin a1c and estimated glomerular filtration rate and iii carotid ultrasound image phenotypes maximum plaque height total plaque area and intra plaque neovascularization baseline characteristics for four classes target labels having significant p 0 0001 values were calculated using chi square and anova for handling the cohort s imbalance in the risk classes ae3 0dl used the synthetic minority over sampling technique smote ae3 0dl used recurrent neural network rnn and long short term memory lstm dl models and the performance accuracy and area under the curve was computed using 10 fold cross validation 90 training 10 testing frameworks ae3 0dl was validated and benchmarked results the ae3 0dl using rnn and lstm showed an accuracy and auc p 0 0001 pairs as 95 00 and 0 98 and 95 34 and 0 99 respectively and showed an improvement of 32 93 and 9 94 against ccvrc and ml respectively ae3 0dl runs in 1s conclusion dl algorithms are a powerful paradigm for coronary artery disease cad risk prediction and cvd risk stratification\n",
      "Score: 1.4688792\n",
      "Title: Deep learning artificial intelligence framework for multiclass coronary artery disease prediction using combination of conventional risk factors carotid ultrasound and intraplaque neovascularization\n",
      "----------\n",
      "cardiovascular diseases cvds account for a significant portion of global mortality emphasizing the need for effective strategies this study focuses on myocardial infarction pulmonary thromboembolism and aortic stenosis aiming to empower medical practitioners with tools for informed decision making and timely interventions drawing from data at hospital santa maria our approach combines exploratory data analysis eda and predictive machine learning ml models guided by the cross industry standard process for data mining crisp dm methodology eda reveals intricate patterns and relationships specific to cardiovascular diseases ml models achieve accuracies above 80 providing a 13 min window to predict myocardial ischemia incidents and intervene proactively this paper presents a proof of concept for real time data and predictive capabilities in enhancing medical strategies\n",
      "Score: 1.4671701\n",
      "Title: AI Driven Decision Support for Early Detection of Cardiac Events Unveiling Patterns and Predicting Myocardial Ischemia\n",
      "----------\n",
      "objective computer vision cv is a subset of artificial intelligence that performs computations on image or video data permitting the quantitative analysis of visual information common cv tasks that may be relevant to surgeons include image classification object detection and tracking and extraction of higher order features despite the potential applications of cv to intraoperative video however few surgeons describe the use of cv a primary roadblock in implementing cv is the lack of a clear workflow to create an intraoperative video dataset to which cv can be applied we report general principles for creating usable surgical video datasets and the result of their applications methods video annotations from cadaveric endoscopic endonasal skull base simulations n 20 trials of 1 5 minutes size 8 gb were reviewed by 2 researcher annotators an internal retrospective analysis of workflow for development of the intraoperative video annotations was performed to identify guiding practices results approximately 34 000 frames of surgical video were annotated key considerations in developing annotation workflows include 1 overcoming software and personnel constraints 2 ensuring adequate storage and access infrastructure 3 optimization and standardization of annotation protocol and 4 operationalizing annotated data potential tools for use include cvat computer vision annotation tool and vott open sourced annotation software allowing for local video storage easy setup and the use of interpolation conclusions cv techniques can be applied to surgical video but challenges for novice users may limit adoption we outline principles in annotation workflow that can mitigate initial challenges groups may have when converting raw video into useable annotated datasets\n",
      "Score: 1.4646966\n",
      "Title: A Guide to Annotation of Neurosurgical Intraoperative Video for Machine Learning Analysis and Computer Vision\n",
      "----------\n",
      "objective cardiovascular disease cvd is one of the leading causes of death worldwide there are many cvd risk estimators but very few take into account sleep features moreover they are rarely tested on patients investigated for obstructive sleep apnea osa however numerous studies have demonstrated that osa index or sleep features are associated with cvd and mortality the aim of this study is to propose a new simple cvd and mortality risk estimator for use in routine sleep testing approach data from a large multicenter cohort of cvd free patients investigated for osa were linked to the french health system to identify new onset cvd clinical features were collected and sleep features were extracted from sleep recordings a machine learning model based on trees adaboost was applied to estimate the cvd and mortality risk score main results after a median inter quartile range follow up of 6 0 3 5 8 5 years 685 of 5234 patients had received a diagnosis of cvd or had died following a selection of features from the original 30 features 9 were selected including five clinical and four sleep oximetry features the final model included age gender hypertension diabetes systolic blood pressure oxygen saturation and pulse rate variability prv features an area under the receiver operating characteristic curve auc of 0 78 was reached significance adaboost an interpretable machine learning model was applied to predict 6 year cvd and mortality in patients investigated for clinical suspicion of osa a mixed set of simple clinical features nocturnal hypoxemia and prv features derived from single channel pulse oximetry were used\n",
      "Score: 1.4646487\n",
      "Title: Cardiovascular risk and mortality prediction in patients suspected of sleep apnea a model based on an artificial intelligence system\n",
      "----------\n",
      "cardiovascular diseases cvd are often characterized by their multifactorial complexity this makes remote monitoring and ambulatory cardiac rehabilitation cr therapy challenging current wearable multimodal devices enable remote monitoring machine learning ml and artificial intelligence ai can help in tackling multifaceted datasets however for clinical acceptance easy interpretability of the ai models is crucial the goal of the present study was to investigate whether a multi parameter sensor could be used during a standardized activity test to interpret functional capacity in the longitudinal follow up of cr patients a total of 129 patients were followed for 3 months during cr using 6 min walking tests 6mwt equipped with a wearable ecg and accelerometer device functional capacity was assessed based on 6mwt distance 6mwd linear and nonlinear interpretable models were explored to predict 6mwd the t distributed stochastic neighboring embedding t sne technique was exploited to embed and visualize high dimensional data the performance of support vector machine svm models combining different features and using different kernel types to predict functional capacity was evaluated the svm model using chronotropic response and effort as input features showed a mean absolute error of 42 8 m 36 8 m the 3d maps derived using the t sne technique visualized the relationship between sensor derived biomarkers and functional capacity which enables tracking of the evolution of patients throughout the cr program the current study showed that wearable monitoring combined with interpretable ml can objectively track clinical progression in a cr population these results pave the road towards ambulatory cr\n",
      "Score: 1.4608293\n",
      "Title: Wearable Monitoring and Interpretable Machine Learning Can Objectively Track Progression in Patients during Cardiac Rehabilitation\n",
      "----------\n",
      "background and motivation cardiovascular disease cvd causes the highest mortality globally with escalating healthcare costs early non invasive cvd risk assessment is vital conventional methods have shown poor performance compared to more recent and fast evolving artificial intelligence ai methods the proposed study reviews the three most recent paradigms for cvd risk assessment namely multiclass multi label and ensemble based methods in i office based and ii stress test laboratories methods a total of 265 cvd based studies were selected using the preferred reporting items for systematic reviews and meta analyses prisma model due to its popularity and recent development the study analyzed the above three paradigms using machine learning ml frameworks we review comprehensively these three methods using attributes such as architecture applications pro and cons scientific validation clinical evaluation and ai risk of bias rob in the cvd framework these ml techniques were then extended under mobile and cloud based infrastructure findings most popular biomarkers used were office based laboratory based image based phenotypes and medication usage surrogate carotid scanning for coronary artery risk prediction had shown promising results ground truth gt selection for ai based training along with scientific and clinical validation is very important for cvd stratification to avoid rob it was observed that the most popular classification paradigm is multiclass followed by the ensemble and multi label the use of deep learning techniques in cvd risk stratification is in a very early stage of development mobile and cloud based ai technologies are more likely to be the future conclusions ai based methods for cvd risk assessment are most promising and successful choice of gt is most vital in ai based models to prevent the rob the amalgamation of image based strategies with conventional risk factors provides the highest stability when using the three cvd paradigms in non cloud and cloud based frameworks\n",
      "Score: 1.4605148\n",
      "Title: A Powerful Paradigm for Cardiovascular Risk Stratification Using Multiclass Multi Label and Ensemble Based Machine Learning Paradigms A Narrative Review\n",
      "----------\n",
      "cardio vascular diseases cvd is the leading cause of death globally and is increasing at an alarming rate according to the american heart association s heart attack and stroke statistics 2021 this increase has been further exacerbated because of the current coronavirus covid 19 pandemic thereby increasing the pressure on existing healthcare resources smart and connected health sch is a viable solution for the prevalent healthcare challenges it can reshape the course of healthcare to be more strategic preventive and custom designed making it more effective with value added services this research endeavors to classify state of the art sch technologies via a thorough literature review and analysis to comprehensively define sch features and identify the enabling technology related challenges in sch adoption we also propose an architectural model that captures the technological aspect of the sch solution its environment and its primary involved stakeholders it serves as a reference model for sch acceptance and implementation we reflected the covid 19 case study illustrating how some countries have tackled the pandemic differently in terms of leveraging the power of different sch technologies such as big data cloud computing internet of things artificial intelligence robotics blockchain and mobile applications in combating the pandemic sch has been used efficiently at different stages such as disease diagnosis virus detection individual monitoring tracking controlling and resource allocation furthermore this review highlights the challenges to sch acceptance as well as the potential research directions for better patient centric healthcare\n",
      "Score: 1.4588276\n",
      "Title: Trends Technologies and Key Challenges in Smart and Connected Healthcare\n",
      "----------\n",
      "cardiovascular diseases cvd is the leading cause of human mortality and morbidity around the world in which myocardial infarction mi is a silent condition that irreversibly damages the heart muscles currently electrocardiogram ecg is widely used by the clinicians to diagnose mi patients due to its inexpensiveness and non invasive nature pathological alterations provoked by mi cause slow conduction by increasing axial resistance on coupling between cells this issue may cause abnormal patterns in the dynamics of the tip of the cardiac vector in the ecg signals however manual interpretation of the pathological alternations induced by mi is a time consuming tedious and subjective task to overcome such disadvantages computer aided diagnosis techniques including signal processing and artificial intelligence tools have been developed in this study we propose a novel technique for automatic detection of mi based on hybrid feature extraction and artificial intelligence tools tunable quality factor q factor wavelet transform tqwt variational mode decomposition vmd and phase space reconstruction psr are utilized to extract representative features to form cardiac vectors with synthesis of the standard 12 lead and frank xyz leads they are combined with neural networks to model identify and detect abnormal patterns in the dynamics of cardiac system caused by mi first 12 lead ecg signals are reduced to 3 dimensional vcg signals which are synthesized with frank xyz leads to build a hybrid 4 dimensional cardiac vector second this vector is decomposed into a set of frequency subbands with a number of decomposition levels by using the tqwt method third vmd is employed to decompose the subband of the 4 dimensional cardiac vector into different intrinsic modes in which the first intrinsic mode contains the majority of the cardiac vector s energy and is considered to be the predominant intrinsic mode it is selected to construct the reference variable for analysis fourth phase space of the reference variable is reconstructed in which the properties associated with the nonlinear cardiac system dynamics are preserved three dimensional 3d psr together with euclidean distance ed has been utilized to derive features which demonstrate significant difference in cardiac system dynamics between normal healthy and mi cardiac vector signals fifth cardiac system dynamics can be modeled and identified using neural networks which employ the ed of 3d psr of the reference variable as the input features the difference of cardiac system dynamics between healthy control and mi cardiac vector is computed and used for the detection of mi based on a bank of estimators finally data sets which include conventional 12 lead and frank xyz leads ecg signal fragments from 148 patients with mi and 52 healthy controls from ptb diagnostic ecg database are used for evaluation by using the 10 fold cross validation style the achieved average classification accuracy is reported to be 97 98 currently st segment evaluation is one of the major and traditional ways for the mi detection however there exist weak or even undetectable\n",
      "Score: 1.4582379\n",
      "Title: Classification of myocardial infarction based on hybrid feature extraction and artificial intelligence tools by adopting tunable Q wavelet transform TQWT variational mode decomposition VMD and neural networks\n",
      "----------\n",
      "advances in high performance computing hpc technology have reached the capacity to inform cardiovascular cv science in the realm of both inductive and constructive approaches clinical trials allow for the comparison of the effect of an intervention without the need to understand the mechanism this is a typical example of an inductive approach in the hpc field training an artificial intelligence ai model constructed by neural networks to predict future cv events with the use of large scale multi dimensional datasets is the counterpart that may rely on as well as inform understanding of mechanistic underpinnings for optimization however in contrast to clinical trials ai can calculate event risk at the individual level and has the potential to inform and refine the application of personalized medicine despite this clear strength results from ai analyses may identify otherwise unidentified unexpected i e non intuitive relationships between multi dimensional data and clinical outcomes that may further unravel potential mechanistic pathways and identify potential therapeutic targets therebycontributing to the parsing of observational associations from causal links the constructive approach will remain critical to overcome limitations of existing knowledge and anchored biases to actualize a more sophisticated understanding of the complex pathobiology of cv diseases hpc technology has the potential to underpin this constructive approach in cv basic and clinical science in general even complex biological phenomena can be reduced to combinations of simple biological chemical physical laws in the deductive approach the focus intent is to explain complex cv diseases by combinations of simple principles\n",
      "Score: 1.4540088\n",
      "Title: The Future Role of High Performance Computing in Cardiovascular Medicine and Science Impact of Multi Dimensional Data Analysis\n",
      "----------\n",
      "purpose monitoring of vital signs at the general ward with continuous assessments aided by artificial intelligence ai is increasingly being explored in the clinical setting this review aims to describe current evidence for continuous vital sign monitoring cvsm with ai based alerts from sensor technology through alert reduction impact on complications and to user experience during implementation recent findings cvsm identifies significantly more vital sign deviations than manual intermittent monitoring this results in high alert generation without ai evaluation both in patients with and without complications current ai is at the rule based level and this potentially reduces irrelevant alerts and identifies patients at need ai aided cvsm identifies complications earlier with reduced staff workload and a potential reduction of severe complications summary the current evidence for ai aided csvm suggest a significant role for the technology in reducing the constant 10 30 in hospital risk of severe postoperative complications however large randomized trials documenting the benefit for patient improvements are still sparse and the clinical uptake of explainable ai to improve implementation needs investigation\n",
      "Score: 1.4536822\n",
      "Title: The future of postoperative vital sign monitoring in general wards improving patient safety through continuous artificial intelligence enabled alert formation and reduction\n",
      "----------\n",
      "objectives we sought to investigate the diagnostic performance of coronary ct angiography ccta derived plaque markers combined with deep machine learning based fractional flow reserve ct ffr to identify lesion specific ischemia using invasive ffr as the reference standard methods eighty four patients 61 10years 65 male who had undergone ccta followed by invasive ffr were included in this single center retrospective irb approved hipaa compliant study various plaque markers were derived from ccta using a semi automatic software prototype and deep machine learning based ct ffr the discriminatory value of plaque markers and ct ffr to identify lesion specific ischemia on a per vessel basis was evaluated using invasive ffr as the reference standard results one hundred three lesion containing vessels were investigated 32 103 lesions were hemodynamically significant by invasive ffr in a multivariate analysis adjusted for framingham risk score the following markers showed predictive value for lesion specific ischemia odds ratio or lesion length or 1 15 p 0 037 non calcified plaque volume or 1 02 p 0 007 napkin ring sign or 5 97 p 0 014 and ct ffr or 0 81 p 0 0001 a receiver operating characteristics analysis showed the benefit of identifying plaque markers over ccta stenosis grading alone with aucs increasing from 0 61 with 50 stenosis to 0 83 with addition of plaque markers to detect lesion specific ischemia further incremental benefit was realized with the addition of ct ffr auc 0 93 conclusion coronary cta derived plaque markers portend predictive value to identify lesion specific ischemia when compared to ccta stenosis grading alone the addition of ct ffr to plaque markers shows incremental discriminatory power key points coronary ct angiography ccta derived quantitative plaque markers of atherosclerosis portend high discriminatory power to identify lesion specific ischemia coronary ct angiography derived fractional flow reserve ct ffr shows superior diagnostic performance over ccta alone in detecting lesion specific ischemia a combination of plaque markers with ct ffr provides incremental discriminatory value for detecting flow limiting stenosis\n",
      "Score: 1.4505627\n",
      "Title: Coronary CT angiography derived plaque quantification with artificial intelligence CT fractional flow reserve for the identification of lesion specific ischemia\n"
     ]
    }
   ],
   "source": [
    "# loop over each returned hit in the search results\n",
    "for result in aux_results[\"hits\"][\"hits\"]:\n",
    "    # print a separator for each result\n",
    "    print(\"-\" * 10)\n",
    "    print(result['_source']['pubmed_text'])\n",
    "    # print the score of the document\n",
    "    print(f\"Score: {result['_score']}\")\n",
    "    # print the title of the document stored in the \"_source\" field\n",
    "    print(f\"Title: {result['_source']['title']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
